---
title: "_monitoraSom_: pacote de R para detecção de sinais usando template matching"
subtitle: "Roteiro para a oficina do I Simpósio de Física aplicada à Ecologia e Conservação"
author: "Gabriel L. M. Rosa"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    number_sections: true
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instalação e setup inicial

Seja bem-vindo(a) ao tutorial do monitoraSom! Nessa primeira etapa, vamos fazer os downloads e instalações necessárias para o uso do monitoraSom.

### 1. Baixar e instalar o R.

- Verifique se já existe alguma versão instalada.
- Ao fazer uma nova instalação, dê preferência para a versão mais recente.
- link para download: https://cran.r-project.org/bin/windows/base/

### 2. Baixar e instalar o Rstudio.
- Após instalar o R, instale o Rstudio.
- Atenção: se houver mais de uma versão do R instalada, certifique-se qual está sendo usada ao abrir o Rstudio.
- link para download: https://posit.co/download/rstudio-desktop/

### 3. Instalar o Rtools (passo necessário apenas para usuários do Windows)
- Rtools é necessário para compilar pacotes do R que foram instalados a partir do GitHub.
- Verifique se já existe alguma versão instalada. Caso exista, verifique se é adequada ao projeto. Se não for, desinstale a versão existente.
- Neste momento, a versão mais recente é a 4.5.
- link para download: https://cran.r-project.org/bin/windows/Rtools/

### 4. Criar uma nova pasta para conter os arquivos usandos pelo monitoraSom.
Para usuários do Windows, recomendamos criar uma pasta para análises na raiz do sistema, e dentro dela uma pasta para este projeto, por exemplo, "C:/Meus Projetos/monitoraSom_tutorial". Dessa forma o caminho para os arquivos será o mesmo mesmo que os arquivos sejam movidos para outro computador.

### 5. Instalar o devtools para poder instalar pacotes a partir do GitHub.
Esse comando deve ser executado no Rstudio após a instalação do Rtools.
```{r eval=FALSE, include=TRUE}
install.packages("devtools")
```

### 6. Carregar o devtools para o ambiente de trabalho.
```{r eval=FALSE, include=TRUE}
library(devtools)
```

### 7. Instalar o monitoraSom
- O monitoraSom depende de outros pacotes do R para funcionar adequadamente.
- Atenção 1: A isntalação poderá solicitar a confirmação de instalação das dependências. Recomendamos que seja feita a instalação ou atualização de todas as dependências respondendo '1' ("All").
- Atenção 2: Pode ser solictada também a resposta sobre instalação de pacotes de precisam de compilação. Nesse caso, responda 'Yes'.
```{r eval=FALSE, include=TRUE}
install_github("ConservaSom/monitoraSom", dependencies = TRUE)
```

### 8. Carregar o monitoraSom no ambiente de trabalho do R para testar a instalação.
```{r message=FALSE, warning=FALSE}
library(monitoraSom)
library(dplyr)
library(ggplot2)
library(patchwork)
```

### 9. Salvar esse script no diretório de trabalho conforme descrito no passo 4.
Priorize salvar com um nome informativo e que mantenha a sequência de passos desse e dos tutoriais seguintes, por exemplo, "script_01_instalação.R".

### Checkpoint 01
Você instalou o monitoraSom e está pronto para começar a usar. Salve esse script no diretório de trabalho conforme descrito no passo 4.

### 10. Organizando o ambiente de trabalho.
Vamos seguir a partir deste ponto assumindo que o diretório de trabalho está organizado conforme descrito no passo 4 e que o código está salvo em um arquivo em formato de script ou notebook (Rmarkdown ou Quarto).

Vamos verificar e, se necessário, ajustar manualmente o diretório de trabalho da sessão atual.
```{r}
getwd()
```

Se o script estiver no diretório de trabalho correto, use o comando abaixo para definir o diretório automaticamente.
```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd() # Verificando se o diretório de trabalho foi definido corretamente
```

Se quiser definir manualmente o diretório de trabalho, use o comando abaixo.
```{r eval=FALSE}
project_path <- paste0(
    "<coloque aqui o caminho para a pasta do projeto>", "/monitoraSom"
)
setwd(project_path)
getwd() # Verificando se o diretório de trabalho foi definido corretamente
```

```{r eval=TRUE, echo=FALSE}
project_path <- paste0(getwd(), "/monitoraSom")
setwd(project_path)
getwd() # Verificando se o diretório de trabalho foi definido corretamente
```

### 11. Povoando o diretório de trabalho com os arquivos de exemplo do monitoraSom.
Use a função `set_workspace` para adicionar os arquivos de exemplo do monitoraSom ao seu diretório de trabalho. Esse comando é recomendado para novos projetos. Evite executá-lo em diretórios que já contenham dados de projetos em andamento. Isso poderá resultar em perdas permanentes de dados.
```{r eval=FALSE}
set_workspace(project_path = "./", example_data = TRUE)
```

Vamos fazer algumas checagens para verificar se os arquivos de exemplo foram depositados corretamente. Em um prjeto recém iniciado, o usuário deverá ter pelo menos os arquivos das soundscapes, e caso deseje extrair templates de outras gravações, uma pasta chamada "recordings". Todos os demais arquivos estão precarregados no pacote para facilitar o uso do monitoraSom. Caso não tenha os arquivos de exemplo, execute o comando `set_workspace` novamente.

Estes são os arquivos das soundscapes onde buscamos a espécie alvo:
```{r}
list.files("./soundscapes/", full.names = TRUE)
```

Estes são os arquivos das gravações focais de onde serão extraídos templates:
```{r}
list.files("./recordings/", full.names = TRUE)
```

Estes são os arquivos com as regiões de interesse determinadas nas gravações focais e soundscapes:
```{r}
list.files("./roi_tables/", full.names = TRUE)
```

### 12. (Opcional) Limpeza de arquivos pre-carregados
Vamos apagar os arquivos de exemplo para continuar o tutorial como um novo projeto. Pule esta etapa se quiser obter os mesmos resultados do tutorial.
```{r eval=FALSE}
file.remove(list.files("./detections/", full.names = TRUE))
file.remove(list.files("./match_grid_metadata/", full.names = TRUE))
file.remove(list.files("./match_scores/", full.names = TRUE))
file.remove(list.files("./soundscapes_metadata/", full.names = TRUE))
file.remove(list.files("./templates/", full.names = TRUE))
file.remove(list.files("./templates_metadata/", full.names = TRUE))
file.remove(list.files("./validation_outputs/", full.names = TRUE))
```

### Checkpoint 02
Você povoou o diretório de trabalho com os arquivos de exemplo do monitoraSom e está pronto para seguir com o uso do pacote. Apague os arquivos de exemplo se quiser começar um novo projeto.

### 13. Usar o app de segmentação para escolher os templates.
Agora vamos usar o app de segmentação para escolher os templates. Note que como estamos somente escolhendo os templates, definimos o destino dos cortes de audio para a pasta "./templates". Os templates são as amostras de som que desejamos usar para detecção nos passos seguintes. Podemos exportar os templates manualmente de dentro do app, mas nesse tutorial vamos usar o app somente para demarcar as ROIs, para depois exportar os cortes de audio automaticamente (ver passo 16).
```{r eval=FALSE}
launch_segmentation_app(
    user = "User", # Nome do usuário
    project_path = "./", # Caminho para a pasta do projeto
    preset_path = "./app_presets/", # Caminho para a pasta de presets
    soundscapes_path = "./recordings/", # Caminho onde ler as gravações
    roi_tables_path = "./roi_tables/", # Caminho para onde exportar as ROIs
    cuts_path = "./templates/", # Caminho para onde exportar cortes de audio
    dyn_range = c(-102, -42), # Ajuste do contraste do espectrograma
    wl = 1024, # Ajuste do comprimento da janela do fft (parametro espectral)
    ovlp = 50, # Ajuste da sobreposição do fft (parametro espectral)
    color_scale = "greyscale 1", # Ajuste da escala de cores do espectrograma
    nav_autosave = TRUE # Auomtação de salvamento ao trocar de soundscape
)
```

### 14. Usar o app de segmentação para segmentar as soundscapes.
Agora vamos usar o app de segmentação para segmentar as soundscapes. Nessa etapa, definimos o destino dos cortes de audio para a pasta "./roi_cuts". As tabelas de ROIs que serão produzidas nessa etapa serão usadas para avaliar as detecções e medir a poerformance de cada template.
```{r eval=FALSE}
launch_segmentation_app(
    user = "User", project_path = "./", preset_path = "./app_presets/",
    soundscapes_path = "./soundscapes/", roi_tables_path = "./roi_tables/",
    dyn_range = c(-102, -42), wl = 1024, ovlp = 50,
    color_scale = "greyscale 1", visible_bp = TRUE, nav_autosave = TRUE
)
```

### 15. Preparando os templates.
Vamos importar todas as tabelas de ROIs para verificarmos se temos o que precisamos. Note que as tabelas de ROIs das soundscapes e dos templates encontram-se na mesma pasta, mas podemos discriminá-las facilmentepelo nome do arquivo.
```{r}
df_rois <- fetch_rois(rois_path = "./roi_tables/")
unique(df_rois$soundscape_file) # Verificando os nomes das gravações
```

Filtrando as tabelas de ROIs para manter somente aquelas com os templates.
```{r}
df_templates <- df_rois %>%
    filter(roi_comment %in% c("Substructure C", "Complete Song")) %>%
    group_by(roi_comment) %>%
    sample_n(1)
glimpse(df_templates)
```

### 16. Exportando os cortes de audio dos templates.
Para exportar os cortes de audio dos templates, usamos a função `export_roi_cuts()`. Note que os cortes de audio serão exportados para a pasta "./templates".
```{r eval=FALSE}
export_roi_cuts(df_rois = df_templates, roi_cuts_path = "./templates/")
list.files(path = "./templates/", pattern = "Bcu", full.names = TRUE)
```

### Checkpoint 03
Aqui você deve decidir: se deseja seguir com o processo simplificado (função `template matching()`) execute o passo 17, ou se deseja seguir com o processo detalhado, execute os passos 18-21.
<!-- todo Definir os passos aqui -->

### 17. Obtendo as detecções (processo simplificado)
Vamos usar o processo simplificado para obter as detecções. Esse processo é mais rápido e fácil, mas menos flexível. Ele é recomendado para projetos pequenos e para quem deseja obter rapidamente os resultados. Nesse caso vamos exportar os resultados para o arquivo "./detections/df_detecs.csv" e usar 4 núcleos para processamento paralelo, para ganhar um pouco de velocidade.
```{r}
template_matching(
    soundscapes_path = "./soundscapes/", # local de origem das soundscapes
    templates_path = "./templates/", # local de origem dos templates
    output_file = "./detections/df_detecs.csv", # resultado (detecções)
    ncores = 4
)
```

### 18. Processando os metadados das soundscapes (processo detalhado).

No processo detalhado, precisamos reunir os metadados das soundscapes e dos templates separadamente. Vamos começar pelas soundscapes.
```{r eval=FALSE}
df_soundscapes <- fetch_soundscape_metadata(
    soundscapes_path = "./soundscapes", # caminho para as soundscapes
    recursive = TRUE, # se TRUE, lê subdiretórios de forma recursiva
    # caminho para onde exportar o arquivo de metadados
    output_file = "./soundscapes_metadata/df_soundscapes.csv",
    ncores = 4, # quantidade de núcleos para processamento paralelo
    # se TRUE, pula o processamento de arquivos já registrados nos metadados
    skip_processed = TRUE
)
glimpse(df_soundscapes)
```

Visualizando rapidamente os espectrogramas das soundscapes para verificar se os arquivos foram importados corretamente.
```{r eval=TRUE, echo=FALSE}
cowplot::plot_grid(
    tuneR::readWave(filename = df_soundscapes$soundscape_path[1]) %>%
        fast_spectro(
            rec = ., f = .@samp.rate, wl = 1024, ovlp = 70,
            dyn_range = c(-102, -42), color_scale = "inferno",
            freq_guide_interval = 0, time_guide_interval = 0,
            tlim = c(0, 30)
        ) +
        theme_bw() +
        theme(legend.position = "none"),
    tuneR::readWave(filename = df_soundscapes$soundscape_path[4]) %>%
        fast_spectro(
            rec = ., f = .@samp.rate, wl = 1024, ovlp = 70,
            dyn_range = c(-102, -42), color_scale = "inferno",
            freq_guide_interval = 0, time_guide_interval = 0,
            tlim = c(0, 30)
        ) +
        theme_bw() +
        theme(legend.position = "none"),
    ncol = 1
)
```

### 19. Processando os metadados dos templates (processo detalhado).
Agora vamos importar os metadados dos templates.
```{r}
df_templates <- fetch_template_metadata(
    templates_path = "./templates/", recursive = TRUE
)
glimpse(df_templates)
```

```{r eval=TRUE, echo=FALSE}
templates_plots <- purrr::map(df_templates$template_path, ~ {
    wav <- tuneR::readWave(filename = .x)
    res <- fast_spectro(
        rec = wav, f = wav@samp.rate, wl = 1024, ovlp = 70,
        dyn_range = c(-102, -42), color_scale = "greyscale 1",
        freq_guide_interval = 0, time_guide_interval = 0,
        flim = c(
            min(df_templates$template_min_freq),
            max(df_templates$template_max_freq)
        )
    ) +
        theme_bw() +
        theme(legend.position = "none")
    return(res)
})
cowplot::plot_grid(
    templates_plots[[1]], templates_plots[[2]],
    ncol = 2, rel_widths = c(1, 0.35)
)
```

### 20. Juntando os metadados das soundscapes e dos templates (processo detalhado).
O template matching pode ser custoso para grandes quantidades de arquivos. O processo detalhado permite filtrar e organizar os dados antes do processamento total. A função `fetch_match_grid()` combina os metadados das soundscapes e templates e checa incompatibilidades, como taxas de amostragem diferentes.
```{r}
df_grid <- fetch_match_grid(
    soundscape_data = df_soundscapes, template_data = df_templates
)
glimpse(df_grid)
```

### 21. Obtendo as detecções (processo detalhado)
Agora vamos rodar o template matching usando a grade produzida acima como referência. Abaixo mostramos como rodar o template matching usando a função `run_matching()` e mais alguns recursos que essa função oferece.
```{r}
run_matching(
    df_grid = df_grid,
    output_file = "./detections/df_detecs.csv", # arquivo com as detecções
    autosave_action = "replace", # ação ao salvar o arquivo
    buffer_size = "template", # buffer para evitar detecções sobrepostas
    ncores = 4 # quantidade de núcleos para processamento em paralelo
)
df_detecs <- read.csv(file = "./detections/df_detecs.csv")
glimpse(df_detecs)
```

Dentre as opções disponíveis para o argumento `autosave_action`, temos:
- "replace": sobrescreve o arquivo existente.
- "append": adiciona os resultados ao arquivo existente, mas deve ser usado com cuidado para evitar detecções duplicadas ao importar o arquivo.

Dentre as opções disponíveis para o argumento `buffer_size`, temos:
- "template": buffer para evitar detecções sobrepostas em uma região de mesma duração do template.
- Valores inteiros: define a quantidade de frames para o buffer.
- 0: desliga o buffer, permitindo detecções sobrepostas em uma região de mesma duração do template. Essa opção é recomendada somente para projetos em que a validação não será realizada manualmente, já que retém muitas detecções redundantes.

Outras opções de filtragem disponíveis são:
- `min_score`: define o score mínimo para detecção. Essa opção determina um limiar mínimo para a detecção, excluindo todas as detecções com scores inferiores ao valor especificado. Deve ser usada com cuidadado, pois pode eliminar completamente soundscapes e templates sem scores acima do limiar especificado, e assim eliminar a possibilidade de contagem correta de FN (False Negatives) para validação a priori (ver passo 23).
- `min_quant`: define o quantil mínimo para detecção. Essa opção avalia o quantil dentro de cada rodada de busca, excluindo todas as detecções com scores inferiores ao quantil especificado. Como o quantil é uma medida relativa, retornará sempre ao menos uma detecção para cada rodada de busca.
- `top_n`: define de forma explícita a quantidade de detecções com os scores mais altos a serem retidas. Essa opção retornará sempre a quantidade de detecções especificada, independente do valor máximo e mínimo de scores obtidos.


### 22. Caso especial: Obtendo os scores brutos.
Vamos usar a função `run_matching()` para fazer as buscas na grade definida, exatamente como no passo 21, mas vamos adicionar o argumento `output = "scores"` para obter os scores brutos ao invés de ir direto para as detecções. Note que mudamos dois argumentos: `output` e `output_file`. `output` define o tipo de resultado que será retornado e `output_file` define o caminho para o arquivo de saída, que agora será um arquivo RDS em vez de CSV.
```{r}
run_matching(
    df_grid = df_grid,
    output = "scores", # arquivo com os scores brutos
    output_file = "./detections/df_scores.rds", # arquivo com os scores brutos
    ncores = 4 # quantidade de núcleos para processamento em paralelo
)
glimpse(df_scores)
```

E importamos o arquivo de scores de volta para o ambiente de trabalho usando a função `readRDS()` seguindo o mesmo caminho do arquivo de saída. Ao inspecionar o objeto importado, vemos que ele retém todas as informações da grade de busca, mas agora com os scores brutos para cada combinação de template e soundscape armazenados como elementos de uma lista no lugar da coluna `score_vec`.
```{r eval=FALSE}
df_scores <- readRDS(file = "./detections/df_scores.rds")
glimpse(df_scores)
```

Para entender melhor como os scores brutos são armazenados, vamos inspecionar o primeiro elemento da lista depositada na coluna `score_vec`. Note que one em um data frame normal seria um valor único, temos outro data frame composto por 2 variáveis, `time_vec`, contendo os valores de tempo em segundos para cada frame do espectrograma da soundscape, e `score_vec`, contendo os scores brutos computados para cada um desses frames.
```{r}
glimpse(df_scores$score_vec[[20]])
```

### 23. Visualizando os scores brutos.
Vamos visualizar os scores brutos para poder entender melhor como as detecções foram produzidas. Notamos nessa primeira versão que precisamos de alguns ajustes para entender melhor o que está acontecendo.
```{r}
plot_scores(df_scores_i = df_scores[7, ])
```

Agora a mesma visualização, mas com os scores ajustados para melhor visualização.
```{r}
plot_scores(
    df_scores_i = df_scores[7, ], ovlp = 90, wl = 1024,
    dyn_range = c(-96, -48), color_scale = "inferno"
)
```

Mais um pouco de zoom agora para ver o pico correspondente a uma detecção mais promissora.
```{r}
plot_scores(
    df_scores_i = df_scores[7, ], ovlp = 70, wl = 1024,
    dyn_range = c(-96, -48), color_scale = "inferno", zoom_time = c(5, 10)
)
```

Como as camadas de filtragem demonstradas no passo 21 ainda não foram aplicadas nesse caso, podemos experimentar as consequencias de aplica-las diretamente sobre os scores brutos nos proprios argumentos da função `plot_scores()`. Para isso vamos remover o zoom para ver o que está acontecendo em toda a extensão da soundscape. Nesse primeiro exemplo vamos deixar o buffer ativo e reter as 10 detecções com os scores mais altos.
```{r}
plot_scores(
    df_scores_i = df_scores[7, ], ovlp = 70, wl = 1024,
    dyn_range = c(-96, -48), color_scale = "inferno",
    buffer_size = "template", top_n = 6
)
```

Agora vamos desligar o buffer e reter somente as detecções com scores acima de 0.1. Podemos ver que nesse caso o limiar de 0.1 ainda não foi suficiente para eliminar todas as detecções que conseguimos ver que são claramente falsas.
```{r}
plot_scores(
    df_scores_i = df_scores[7, ], ovlp = 70, wl = 1024,
    dyn_range = c(-96, -48), color_scale = "inferno",
    buffer_size = 0, min_score = 0.1
)
```

```{r}
plot_scores(
    df_scores_i = df_scores[11, ], ovlp = 70, wl = 1024,
    dyn_range = c(-96, -48), color_scale = "inferno",
    buffer_size = "template", min_score = 0.1
)
```

A avaliação visual ajuda no ajuste inicial, mas não basta para escolher o melhor limiar. É preciso validar as detecções para definir o corte ideal de score para todo o conjunto de soundscapes. Antes prosseguir, vamos extrair as detecções desejadas a partir do arquivo de scores brutos, mas agora retendo todas as detecções, sem aplicar nenhum filtro. Note que temos 41,732 detecções no total.

```{r}
df_detecs_nofilt <- fetch_score_peaks(
    df_scores = df_scores,
    buffer_size = 0,
    output_file = "./detections/df_detecs_nofilt.csv"
)
glimpse(df_detecs_nofilt)
```

### Checkpoint 04
Você obteve as detecções, mas veja que ainda não sabe quais são verdadeiras ou falsas. Nesse checkpoint você poderá fazer fitragens adicionais às demonstradas no passo acima segundo os critérios do seu projeto. Nesse ponto será necessário determinar qual método de validação será usado.

### 23. Validando as detecções (método a priori)
O método de validação a priori é o mais completo e rápido, pois é baseado na sobreposição temporal entre as detecções e as ROIs para a classificação de cada detecção como verdadeira ou falsa. Esse método é recomendado sempre que dados de segmentação estiverem disponíveis, pois permite a contagem correta de FN (False Negatives), a partir das ROIs que não foram alcançadas por nenhuma detecção. Nesse caso vamos usar a função `validate_by_overlap()` para validar as detecções.
```{r}
df_validated <- validate_by_overlap(
    df_detecs = df_detecs, df_rois = df_rois, validation_user = "User"
)
glimpse(df_validated)
```

### 24. Checagens sanitárias das detecções validadas.
Inspecionando o objeto com os resultados da validação, podemos ver todas as variáveis da tabela de detecções, mas agora também agregamos dados sobre as ROIs para os casos de correspondência, revelando todos os pares de detecção x ROI, bem como as ROIs que não foram alcançadas por nenhuma detecção. O status de cada detecção é armazenado na coluna `validation`, que pode ter os valores `TP` (verdadeiro positivo ou detecção confirmada ), `FP` (falso positivo ou detecção falsa) ou `FN` (falso negativo ou detecção não alcançada). Vejamos as contagens dessa classificação para cada template.
```{r}
table(df_validated$validation, df_validated$template_name)
```

Mas antes disso, vamos relembrar a quantidade de detecções que obtivemos com cada método. A versão não filtrada tem 41,732 detecções, enquanto a versão filtrada tem 4,363 detecções..
```{r}
nrow(df_detecs)
nrow(df_detecs_nofilt)
```

É importante ressaltar que tanto `df_detecs`, sua versão não filtrada, quanto `df_validated`, reunem as detecções e detecções validades de todos os templates de forma agregada, apesar dos processos serem computados separadamente para cada template.

Vamos comparar o desempenho do método de validação a priori em diferentes cenários. Ao aplicar a validação na versão filtrada das detecções, temos um processo rápido devido à menor quantidade de detecções. Já na versão não filtrada, o número de detecções é consideravelmente maior, e, ainda assim, o tempo de processamento permaneceu eficiente. Isso mostra que mesmo trabalhando com grandes volumes de dados, a validação automática ocorre de forma muito rápida. Portanto, além de permitir a validação da totalidade das detecções, a abordagem automatizada elimina a necessidade de checagem manual, sendo muito mais ágil e prática do que o método manual (a posteriori), apresentado a seguir. Por isso, nós, os desenvolvedores, recomendamos o uso do método de validação a priori sempre que possível.
```{r}
# Cronometrando o tempo de processamento da validação das detecs filtradas
system.time({
    validate_by_overlap(
        df_detecs = df_detecs, df_rois = df_rois, validation_user = "User"
    )
})
# Cronometrando o tempo de processamento da validação das detecs não filtradas
system.time({
    validate_by_overlap(
        df_detecs = df_detecs_nofilt, df_rois = df_rois, validation_user = "User"
    )
})
```

### 25. Validando as detecções (método a posteriori)
Quando não temos dados de segmentação manual, podemos validar as detecções manualmente. Nesse caso vamos usar o app de validação manual do monitoraSom. Mas antes de prosseguir, vamos fazer uma cópia da tabela de detecções para não perdermos os dados originais.
```{r eval=FALSE}
file.copy(
    from = "./detections/df_detecs.csv",
    to = "./detections/df_detecs_aposteriori.csv",
    overwrite = FALSE # para evitar sobrescrever a cópia, caso já exista
)
```

Agora vamos usar o app de validação manual para validar as detecções.
```{r}
launch_validation_app(
    project_path = ".", validation_user = "User",
    templates_path = "./templates/", soundscapes_path = "./soundscapes/",
    input_path = "./detections/df_detecs_aposteriori.csv",
    output_path = "./detections/df_detecs_aposteriori.csv",
    dyn_range_templ = c(-78, -30), dyn_range_detec = c(-78, -30), wl = 1024,
    ovlp = 70, time_guide_interval = 0, freq_guide_interval = 0,
    overwrite = TRUE
)
```

### 26. Importando e inspecionando os resultados da validação a posteriori.
Agora vamos importar o arquivo de detecções validadas de volta para o ambiente de trabalho usando a função `read.csv()` seguindo o mesmo caminho do arquivo de saída.
```{r}
df_detecs_aposteriori <- read.csv(
    file = "./detections/df_detecs_aposteriori.csv"
)
glimpse(df_detecs_aposteriori)
```

NV = not validated
```{r}
table(
    df_detecs_aposteriori$validation, df_detecs_aposteriori$template_name
)
```

### 27. Comparando os resultados das validações a priori e a posteriori.
Vamos comparar os resultados das validações a priori e a posteriori.
```{r}
df_rois %>%
    filter(!grepl("Bcu", soundscape_file)) %>%
    nrow()

nrow(df_detecs_aposteriori)
table(df_detecs_aposteriori$validation, df_detecs_aposteriori$template_name)
```

### 28. Diagnósticos de performance.

Quando trabalhamos com detecção automática, especialmente utilizando métodos como template matching, é fundamental avaliar métricas de performance como a precision (precisão) e recall ou sensitivity (sensibilidade). A precisão quantifica quantas das detecções obtidas estão corretas, enquanto o recall mede quantas das ocorrências dos sinais alvo foram de fato detectadas.

Essas métricas geralmente apresentam uma relação de toma-lá-dá-cá: aumentar o limiar para considerar detecções verdadeiras pode aumentar a precisão (menos FP), mas também pode diminuir o recall (mais FN). Por outro lado, abaixar o limiar pode aumentar o recall mas reduzir a precisão. Portanto, avaliar os resultados em termos de precision e recall é essencial para escolher o limiar ideal do template matching para seu objetivo, seja ele minimizar falsos positivos, maximizar a recuperação de eventos ou buscar um equilíbrio entre ambos.

A função `diagnostic_validations()` produz uma lista com os diagnósticos de performance para cada template.
```{r}
ls_val_apriori <- diagnostic_validations(
    df_validated = df_validated, pos_prob = 0.90, val_a_priori = TRUE
)
# Separando os resultados para cada template
res_template1 <- ls_val_apriori[[1]]
res_template2 <- ls_val_apriori[[2]]
```

Inspecionando os diagnósticos de performance para cada template. Os dataframes contém todas as métricas de performance para cada template em função dos limiares de score avaliados.
```{r}
res_template1$diagnostics %>% glimpse()
res_template2$diagnostics %>% glimpse()
```

Nos resultados de cada templates também temos disponíveis os gráficos de métricas de performance em função dos limiares de score avaliados. Na primeira coluna temos os dados do primeiro template, aquele composto somete pela parte final do canto, enquanto na segunda coluna temos os dados do segundo template, aquele composto pelo canto completo. Na primeira linha temos os gráficos dos modelos binomiais, nos quais definimos o score com a probabilidade posterior de 95% da detecção ser verdadeira. Na segunda linha mostramos os gráficos de precisão e recall em função dos limiares de score avaliados. Em todos os casos as linhas vermelhas representam os níveis de score selecionados para cada template
```{r}
cowplot::plot_grid(
    res_template1$mod_plot, res_template2$mod_plot,
    res_template1$precrec_plot, res_template2$precrec_plot,
    ncol = 2
)
```

### 29. Obtendo o conjunto final de detecções.

```{r}
res_template1$score_cut

res_template2$score_cut

detecs1 <- df_detecs %>%
    filter(
        template_name == res_template1$diagnostics$template_name[1] &
        peak_score >= res_template1$score_cut
    ) %>%
    glimpse()

detecs2 <- df_detecs %>%
    filter(
        template_name == res_template2$diagnostics$template_name[1] &
        peak_score >= res_template2$score_cut
    ) %>%
    glimpse()

```

```{r}

detection_plots1 <- detecs1 %>%
    split(., seq(nrow(.))) %>%
    purrr::map(., ~ {
        wav <- tuneR::readWave(
            filename = .x$soundscape_path, from = .x$detection_start, to = .x$detection_end, units = "seconds"
        )
        res <- fast_spectro(
            rec = wav, f = wav@samp.rate, wl = 512, ovlp = 70,
            dyn_range = c(-102, -42), color_scale = "greyscale 1",
            freq_guide_interval = 0, time_guide_interval = 0,
            zoom_freq = c(
                .x$template_min_freq,
                .x$template_max_freq
            )
        ) +
            theme_bw() +
            theme(legend.position = "none")
        return(res)
    }, .progress = TRUE)
length(detection_plots1)


cowplot::plot_grid(
    detection_plots1[[1]], detection_plots1[[2]],
    detection_plots1[[3]], detection_plots1[[4]],
    detection_plots1[[5]], detection_plots1[[6]],
    ncol = 3
)
```


```{r}

detection_plots2 <- detecs2 %>%
    split(., seq(nrow(.))) %>%
    purrr::map(., ~ {
        wav <- tuneR::readWave(
            filename = .x$soundscape_path, from = .x$detection_start, to = .x$detection_end, units = "seconds"
        )
        res <- fast_spectro(
            rec = wav, f = wav@samp.rate, wl = 512, ovlp = 70,
            dyn_range = c(-102, -42), color_scale = "greyscale 1",
            freq_guide_interval = 0, time_guide_interval = 0,
            zoom_freq = c(
                .x$template_min_freq,
                .x$template_max_freq
            )
        ) +
            theme_bw() +
            theme(legend.position = "none")
        return(res)
    }, .progress = TRUE)
length(detection_plots2)


cowplot::plot_grid(
    detection_plots2[[1]], detection_plots2[[2]],
    detection_plots2[[3]], detection_plots2[[4]],
    detection_plots2[[5]], detection_plots2[[6]],
    detection_plots2[[7]], detection_plots2[[8]],
    detection_plots2[[9]], detection_plots2[[10]],
    detection_plots2[[11]], detection_plots2[[12]],
    detection_plots2[[13]],
    ncol = 5
)
```